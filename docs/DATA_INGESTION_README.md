# Data Ingestion Workflow with LLM Self-Correction

## Overview

This system provides a complete data ingestion pipeline where:
1. **NO Julia code is written manually** - the LLM generates all Julia code
2. Files are previewed (first 30 rows) to give context to the LLM
3. The LLM generates Julia code to convert files to Parquet
4. Errors are captured and sent back to the LLM for self-correction
5. All debug information is stored for analysis

## Workflow Steps

### Step 1: File Preview
The system attempts to preview any data file to extract:
- First 30 rows of data
- Column names and types
- File metadata (size, format, etc.)

This preview is passed to the LLM as context.

### Step 2: LLM Code Generation
The LLM receives:
- File preview data
- Available Julia packages list
- Target database path
- Task requirements

And generates complete Julia code to:
- Read the full file
- Convert to Parquet
- Store metadata in DuckDB
- Run verification queries

### Step 3: Execution with Error Capture
The generated Julia code is executed with full logging:
```julia
[LOG] Starting data ingestion process...
[LOG] Reading file: data.csv
[LOG] ✅ File read successfully
[LOG] Shape: (1000, 10)
[LOG] Converting to Parquet...
[LOG] ✅ Parquet file created
[LOG] Storing metadata in DuckDB...
[SUCCESS] Data ingestion completed!
```

### Step 4: Error Handling & Self-Correction
If an error occurs:
1. The error message is captured
2. Sent back to the LLM with the original context
3. LLM generates corrected code
4. Process repeats (max 3 attempts)

Example error feedback to LLM:
```
The previous Julia code failed with error:
"MethodError: no method matching read_xlsx(::String)"

Please fix the code. The file is an Excel file at path: data.xlsx
Available packages: XLSX, DataFrames, Parquet
```

### Step 5: Debug Information Storage
All information is stored including:
- Each attempt's generated code
- Execution logs (stdout/stderr)
- Error messages
- Timestamps
- Final success/failure status
- Rows processed

## Supported File Types

| File Type | Primary Method | Fallback Method | Julia Package |
|-----------|---------------|-----------------|---------------|
| CSV | Rust csv crate | Julia CSV.jl | CSV |
| Parquet | Rust arrow | Julia Parquet.jl | Parquet |
| Excel (.xlsx, .xls) | Julia XLSX.jl | - | XLSX |
| JSON | Rust serde_json | Julia JSON.jl | JSON |

## Debug Information Structure

```json
{
  "ingestion_id": 4523,
  "timestamp": "2024-01-20T10:30:00Z",
  "attempts": [
    {
      "attempt": 1,
      "step": "preview",
      "preview_method": "rust",
      "preview_length": 2048
    },
    {
      "attempt": 1,
      "step": "llm_prompt",
      "prompt_length": 1500
    },
    {
      "attempt": 1,
      "step": "generated_code",
      "code_length": 2500,
      "code": "using CSV, DataFrames..."
    },
    {
      "attempt": 1,
      "step": "execution",
      "success": false,
      "error": "MethodError: ...",
      "stderr": "Error details..."
    },
    {
      "attempt": 2,
      "step": "llm_retry",
      "corrected_code": "using XLSX..."
    },
    {
      "attempt": 2,
      "step": "execution",
      "success": true,
      "stdout": "[LOG] Success...",
      "rows_processed": 1000
    }
  ],
  "final_status": "success",
  "total_rows": 1000,
  "parquet_file": "/path/to/data.parquet"
}
```

## Running the Demo

```bash
# Install required Julia packages
julia -e 'using Pkg; Pkg.add(["CSV", "DataFrames", "Parquet", "XLSX", "DuckDB"])'

# Run the demo workflow
julia demo_ingestion_workflow.jl

# Or in Julia REPL
julia> include("demo_ingestion_workflow.jl")
julia> demo_complete_workflow()
```

## Key Features

### 1. No Manual Julia Coding
- All Julia code is generated by the LLM
- System only provides file preview and context

### 2. Self-Correcting
- Errors are automatically sent back to LLM
- LLM learns from errors and corrects its code
- Up to 3 retry attempts

### 3. Comprehensive Logging
```julia
# Every step is logged
println("[LOG] Starting process...")
println("[LOG] Reading file: $filepath")
println("[LOG] Shape: $(size(df))")
println("[ERROR] Failed: $error_msg")
println("[SUCCESS] Completed!")
```

### 4. Multiple File Format Support
- Automatically detects file type by extension
- Falls back to Julia if Rust preview fails
- Passes appropriate package info to LLM

### 5. Debug Traceability
- Every attempt is recorded
- All generated code is stored
- Complete execution logs preserved
- Can replay/analyze failures

## Error Handling Examples

### Example 1: Missing Package
```
Error: "UndefVarError: XLSX not defined"
LLM Response: Adds "using XLSX" to the code
```

### Example 2: Wrong Method
```
Error: "MethodError: no method matching read_excel"
LLM Response: Changes to XLSX.readxlsx()
```

### Example 3: Type Mismatch
```
Error: "TypeError: expected String, got Symbol"
LLM Response: Converts symbols to strings
```

## Integration with Cedar CLI

When integrated with cedar-cli:
```bash
# Process any file - LLM figures out how
./cedar-cli ingest data.xlsx --debug

# View debug info
./cedar-cli show-debug --ingestion-id 4523

# Retry with modifications
./cedar-cli retry --ingestion-id 4523 --max-attempts 5
```

## Benefits

1. **No Julia expertise required** - LLM handles all Julia code
2. **Self-healing** - Errors are automatically corrected
3. **Extensible** - Just add new packages, LLM will use them
4. **Debuggable** - Complete audit trail of all attempts
5. **Flexible** - Handles any file format the LLM knows about

## Next Steps

To extend this system:
1. Add more file preview methods in Rust
2. Include more Julia packages in the environment
3. Store debug info in actual database (not just JSON)
4. Add data quality checks to the LLM prompts
5. Cache successful code patterns for similar files

## Important Notes

- The LLM needs to know which Julia packages are available
- File previews should be comprehensive but concise (30 rows max)
- Error messages must be complete for LLM to fix issues
- Debug info should capture everything for post-mortem analysis
- Always verify Parquet output matches source data
